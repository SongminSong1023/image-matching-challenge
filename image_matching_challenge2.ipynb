{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","authorship_tag":"ABX9TyN0b+VHi9IQyWvIzcu0Csf+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"po2DFMBJWcwu"},"outputs":[],"source":["!pip install torchsummary timm scikit-learn faiss-cpu -q"]},{"cell_type":"code","source":["import warnings, os, copy, time, json, pickle, numpy as np, torch, torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Subset\n","from torchvision import datasets, transforms, models\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics  import accuracy_score, classification_report, top_k_accuracy_score\n","from pathlib import Path\n","from tqdm.auto import tqdm\n","import timm\n","import torch.nn.functional as F\n","from torch.utils.data import WeightedRandomSampler\n","import faiss\n","\n","SEED          = 42\n","torch.manual_seed(SEED); np.random.seed(SEED)"],"metadata":{"id":"m_kIGrP1Widf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#!git clone https://github.com/hbcbh1999/recaptcha-dataset.git"],"metadata":{"id":"JBQUY6svWleX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#!rm -rf ./recaptcha-dataset/Large/Mountain/\n","#!rm -rf ./recaptcha-dataset/Large/Other/\n","#!rm -rf ./recaptcha-dataset/Large/readme.txt"],"metadata":{"id":"HvzaDzuPWnyY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"V8ZK9qX_9WWI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["CLASS_NAMES   = ['Bicycle','Bridge','Bus','Car','Chimney',\n","                 'Crosswalk','Hydrant','Motorcycle','Palm','Traffic Light']\n","ROOT_DRIVE = Path('/content/drive/MyDrive/image_matching_challenge')\n","DATA_DIR      = ROOT_DRIVE / 'db_images'\n","MODEL_DIR  = ROOT_DRIVE / 'models'\n","FEAT_DIR   = ROOT_DRIVE / 'feature_spaces'\n","MODEL_DIR.mkdir(parents=True, exist_ok=True)\n","FEAT_DIR.mkdir(parents=True, exist_ok=True)\n","NUM_CLASSES   = len(CLASS_NAMES)\n","IMG_SIZE      = 224\n","BATCH_SIZE    = 16            # Convnext: 32 ResNet: 16\n","NUM_EPOCHS    = 20\n","LR            = 3e-4\n","MODEL_NAME    = 'resnet152'    # 'convnext_tiny' | 'resnet152' | 'efficientnet_b3' | 'mobilenet_v3_large' | 'densenet201'\n","WEIGHTS_OUT   = MODEL_DIR / f'{MODEL_NAME}_best.pth'\n","FEAT_CACHE    = FEAT_DIR / f'{MODEL_NAME}_features.npz'\n","KNN_PKL       = MODEL_DIR / f'{MODEL_NAME}_knn.pkl'\n","\n","\n","# í”Œëž˜ê·¸: True â†’ ìƒˆë¡œ í•™ìŠµ / False â†’ ì €ìž¥ë³¸ ë¡œë”©\n","TRAIN_CNN     = not WEIGHTS_OUT.exists()\n","EXTRACT_FEATS = not FEAT_CACHE.exists()\n","FIT_KNN       = not KNN_PKL.exists()\n","\n","n_cls = 10\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print('device =', device)\n","\n","torch.cuda.empty_cache()"],"metadata":{"id":"X8u_Phm7W5Kh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","Performing data augmentation and setting dataloader\n","\"\"\"\n","train_tfms = transforms.Compose([\n","    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n","    transforms.RandomHorizontalFlip(), transforms.RandomRotation(10),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n","])\n","val_tfms = transforms.Compose([\n","    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n","])\n","\n","full_ds = datasets.ImageFolder(DATA_DIR, transform=train_tfms)\n","indices = np.random.permutation(len(full_ds))\n","split   = int(0.8*len(full_ds))\n","train_idx, val_idx = indices[:split], indices[split:]\n","\n","train_ds = Subset(full_ds, train_idx)\n","val_ds   = Subset(copy.deepcopy(full_ds), val_idx)\n","val_ds.dataset.transform = val_tfms\n","\n","targets_arr  = np.array([t for _, t in full_ds.samples])\n","class_counts = np.bincount(targets_arr, minlength=len(CLASS_NAMES))\n","weights      = 1. / class_counts[targets_arr[train_idx]]\n","weights = torch.as_tensor(weights, dtype=torch.double)\n","weights      = torch.DoubleTensor(weights)\n","train_sampler= WeightedRandomSampler(weights, len(weights), replacement=True)\n","\n","dataloaders = {\n","    'train': DataLoader(train_ds, batch_size=BATCH_SIZE,\n","                        sampler=train_sampler, num_workers=2, pin_memory=True, persistent_workers=False),\n","    'val'  : DataLoader(val_ds,   batch_size=BATCH_SIZE,\n","                        shuffle=False, num_workers=2, pin_memory=True, persistent_workers=False)\n","}\n","print(f\"train / val = {len(train_ds)} / {len(val_ds)}\")\n","\n","\n","class BalancedSoftmaxCE(nn.Module):\n","    def __init__(self, cls_cnt):\n","        super().__init__()\n","        freq = torch.tensor(cls_cnt, dtype=torch.float32)\n","        self.log_freq = (freq / freq.sum()).log()\n","\n","    def forward(self, logits, target):\n","        return F.cross_entropy(logits + self.log_freq.to(logits.device), target)\n","\n","class ArcFaceLoss(nn.Module):\n","    def __init__(self, in_feat, n_cls, s=30.0, m=0.50):\n","        super().__init__()\n","        self.W = nn.Parameter(torch.randn(n_cls, in_feat))\n","        nn.init.xavier_uniform_(self.W); self.s, self.m = s, m\n","\n","    def forward(self, emb, label):\n","        emb = F.normalize(emb); W = F.normalize(self.W)\n","        cos = F.linear(emb, W).clamp(-1+1e-7, 1-1e-7)\n","        theta = torch.acos(cos); target_cos = torch.cos(theta + self.m)\n","        onehot = torch.zeros_like(cos); onehot.scatter_(1, label.view(-1,1), 1.)\n","        logits = cos*(1-onehot) + target_cos*onehot\n","        return F.cross_entropy(self.s*logits, label)"],"metadata":{"id":"9zQmiJETWqDL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","Building Model\n","\"\"\"\n","\n","def logits_from_emb(model, emb):\n","    if hasattr(model, 'get_classifier'):          # timm ConvNeXtÂ·ViT â€¦\n","        return model.get_classifier()(emb)\n","    elif hasattr(model, 'fc'):                    # torchvision ResNet\n","        return model.fc(emb)\n","    elif hasattr(model, 'classifier'):            # EfficientNetÂ·DenseNet ë“±\n","        return model.classifier(emb)\n","    else:\n","        raise RuntimeError(\"No classifier head found!\")\n","\n","def build_model(name:str, n_cls:int):\n","    if name.startswith('convnext'):\n","        model = timm.create_model(name, pretrained=True,\n","                                  num_classes=n_cls, global_pool='avg')\n","        in_feat = model.num_features\n","        feat_forward = lambda x: torch.flatten(\n","            model.head.global_pool(model.forward_features(x)), 1)\n","\n","    elif name == 'resnet152':\n","        model = models.resnet152(weights=models.ResNet152_Weights.IMAGENET1K_V2)\n","        in_feat = model.fc.in_features; model.fc = nn.Linear(in_feat, n_cls)\n","        feat_forward = lambda x: torch.flatten(model.avgpool(\n","            model.layer4(model.layer3(model.layer2(model.layer1(\n","            model.relu(model.bn1(model.conv1(x)))))))),1)\n","\n","    elif name.startswith('efficientnet'):\n","        model = models.__dict__[name](weights='IMAGENET1K_V1')\n","        # ë§ˆì§€ë§‰ Linear êµì²´\n","        in_feat = model.classifier[-1].in_features\n","        model.classifier[-1] = nn.Linear(in_feat, n_cls)\n","        # feature ì¶”ì¶œ í•¨ìˆ˜\n","        feat_forward = lambda x: torch.flatten(\n","            model.avgpool(model.features(x)), 1)\n","    else: raise ValueError(\"ì§€ì›ë˜ì§€ ì•ŠëŠ” ëª¨ë¸\")\n","    return model.to(device), feat_forward, in_feat\n","\n","model, feat_forward, EMB_DIM = build_model(MODEL_NAME, len(CLASS_NAMES))\n","print(f\"{MODEL_NAME}: {sum(p.numel() for p in model.parameters())/1e6:.2f}M params, feat_dim={EMB_DIM}\")\n","\n","# -----------------------------------------------------------\n","# 2-1. í•™ìŠµ ë£¨í”„\n","# -----------------------------------------------------------\n","if TRAIN_CNN:\n","    print(\">>> training CNN with BalancedSoftmax + ArcFace\")\n","    crit_bs = BalancedSoftmaxCE(class_counts).to(device)\n","    arcloss = ArcFaceLoss(EMB_DIM, len(CLASS_NAMES)).to(device)\n","    optimizer = optim.AdamW(list(model.parameters())+list(arcloss.parameters()),\n","                            lr=LR, weight_decay=1e-2)\n","    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS)\n","\n","    best_acc, best_wts = 0., copy.deepcopy(model.state_dict())\n","    for epoch in range(NUM_EPOCHS):\n","        print(f\"\\n[Epoch {epoch+1}/{NUM_EPOCHS}]\")\n","        for phase in ('train','val'):\n","            model.train() if phase=='train' else model.eval()\n","            tot_loss = tot_hit = 0\n","            for X, y in tqdm(dataloaders[phase], leave=False):\n","                X, y = X.to(device, non_blocking=True), y.to(device, non_blocking=True)\n","                optimizer.zero_grad(set_to_none=True)\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    emb = feat_forward(X)                  # â‘  ë°±ë³¸ 1íšŒ\n","                    if emb.dim() == 4:                     # â‘¡ (B,C,H,W)â†’(B,C)\n","                        emb = emb.mean(dim=[2, 3])\n","                    logits = logits_from_emb(model, emb)   # â‘¢ FCë§Œ í˜¸ì¶œ\n","                    loss   = crit_bs(logits, y) + 0.5 * arcloss(emb, y)\n","                    if phase == 'train':\n","                        loss.backward(); optimizer.step()\n","                tot_loss += loss.item()*len(X)\n","                tot_hit  += (logits.argmax(1)==y).sum().item()\n","\n","            epoch_loss = tot_loss/len(dataloaders[phase].dataset)\n","            epoch_acc  = tot_hit / len(dataloaders[phase].dataset)\n","            print(f\" {phase:5s} | loss {epoch_loss:.4f} | acc {epoch_acc:.4f}\")\n","            if phase=='val' and epoch_acc > best_acc:\n","                best_acc = epoch_acc\n","                best_wts = {k: v.cpu().clone() for k,v in model.state_dict().items()}\n","        scheduler.step()\n","\n","    print(f\"\\nBest val acc = {best_acc:.4f}\")\n","    torch.save(best_wts, WEIGHTS_OUT)\n","else:\n","    print(\">>> Found weights â€“ loading\")\n","    model.load_state_dict(torch.load(WEIGHTS_OUT, map_location=device))\n"],"metadata":{"id":"B3anH1taXpBt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","Caching feature vector\n","\"\"\"\n","def extract_feats(dataset, batch=BATCH_SIZE):\n","    loader = DataLoader(dataset, batch_size=batch, shuffle=False,\n","                        num_workers=0, pin_memory=True)\n","    feats, labels = [], []\n","    model.eval()\n","    with torch.inference_mode():\n","        for X,y in tqdm(loader, desc=\"extract\"):\n","            X = X.to(device)\n","            f = feat_forward(X)              # (B,C,H,W) ë˜ëŠ” (B,C)\n","            if f.dim() == 4:                 # â–² FIX: ê³µê°„ í‰ê· \n","                f = f.mean(dim=[2,3])        # (B,C)\n","            f = F.normalize(f, p=2, dim=1)   # â–² FIX: ì´ì œ L2\n","            feats.append(f.cpu()); labels.append(y)\n","    paths = [dataset.dataset.samples[i][0] for i in dataset.indices] \\\n","            if isinstance(dataset, Subset) \\\n","            else [p for p,_ in dataset.samples]\n","    return torch.cat(feats).numpy(), torch.cat(labels).numpy(), np.array(paths)\n","\n","if EXTRACT_FEATS:\n","    full_ds_eval           = copy.deepcopy(full_ds)\n","    full_ds_eval.transform = val_tfms\n","    feats, labels, paths   = extract_feats(full_ds_eval)\n","    np.savez_compressed(FEAT_CACHE, feats=feats, labels=labels, paths=paths)\n","else:\n","    data   = np.load(FEAT_CACHE, allow_pickle=True)\n","    feats, labels, paths = data['feats'], data['labels'], data['paths']"],"metadata":{"id":"sEb19Y03X7hL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_feats, val_feats = feats[train_idx], feats[val_idx]\n","train_lbls , val_lbls  = labels[train_idx], labels[val_idx]\n","\n","gallery_feats = feats\n","gallery_lbls  = labels\n","\n","if FIT_KNN:\n","    knn = KNeighborsClassifier(n_neighbors=5, metric='cosine', weights='distance')\n","    knn.fit(gallery_feats, gallery_lbls)         # â˜…MOD\n","    with open(KNN_PKL, 'wb') as f: pickle.dump(knn, f)\n","else:\n","    with open(KNN_PKL, 'rb') as f: knn = pickle.load(f)\n","\n","val_pred = knn.predict(val_feats)\n","print(\"\\nKNN val ACC =\", accuracy_score(val_lbls, val_pred))\n","print(classification_report(val_lbls, val_pred, target_names=CLASS_NAMES, digits=3))\n","\n","# ----- (ì„ íƒ) Faiss ì¸ë±ìŠ¤ â€“ ëŒ€ê·œëª¨ìš© ----------\n","# faiss_index = faiss.IndexFlatIP(train_feats.shape[1])\n","# faiss_index.add(train_feats.astype('float32'))\n","\n","def k_reciprocal_rerank(qf, gf, initial_rank, k1=20, k2=6, lamb=0.3):\n","    cos   = (gf @ qf.T).squeeze(); dist = 1 - cos\n","    V = np.zeros_like(dist)\n","    for i in initial_rank[:k1]:\n","        sim_i = gf @ gf[i]; ind_i = sim_i.argsort()[-k2:]\n","        V[i] = sim_i[ind_i].mean()\n","    V = (V - V.min()) / (V.max() - V.min() + 1e-12)\n","    return ((1-lamb)*dist + lamb*(1-V)).argsort()\n","\n","def retrieve(query_idx: int, k: int = 10, k1: int = 20, k2: int = 6, lamb: float = 0.3):\n","    \"\"\"\n","    â€¢ query_idx : val ì„¸íŠ¸ì—ì„œ ì§ˆì˜ë¡œ ì“¸ ì¸ë±ìŠ¤\n","    â€¢ k         : ìµœì¢…ìœ¼ë¡œ ëŒë ¤ì¤„ ê°œìˆ˜\n","    \"\"\"\n","    # 1) ì¿¼ë¦¬â€†Â·â€†ê°¤ëŸ¬ë¦¬ feature\n","    qf = val_feats[query_idx]                       # shape (D,)\n","    gf = gallery_feats                             # shape (N, D)\n","\n","    # 2) cosine ê±°ë¦¬ (= 1â€†â€“â€†cosine similarity) ì „ì²´ ê³„ì‚°\n","    cos_all  = gf @ qf               # similarity  (N,)\n","    dist_all = 1.0 - cos_all         # distance    (N,)\n","\n","    # 3) ì´ˆê¸° ëž­í¬ & k-reciprocal re-rank\n","    init_rank = dist_all.argsort()[:50]            # 50 ê°œ ì •ë„ë©´ ì¶©ë¶„\n","    rank      = k_reciprocal_rerank(qf, gf, init_rank,\n","                                    k1=k1, k2=k2, lamb=lamb)\n","\n","    # 4) ìµœì¢… ìƒìœ„ k\n","    final_idx = rank[:k]\n","    neigh_info = [\n","        (paths[i],\n","         CLASS_NAMES[gallery_lbls[i]],\n","         float(dist_all[i]))\n","        for i in final_idx\n","    ]\n","    return neigh_info\n","\n","print(\"\\n[Query ì˜ˆì‹œ]\")\n","for r,(p,c,d) in enumerate(retrieve(0,10),1):\n","    print(f\"{r:02d}. {Path(p).name:30s} | {c:12s} | dist={d:.4f}\")"],"metadata":{"id":"bSjxNIWQZV6v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","Performing classification and retrieval for query images\n","\"\"\"\n","\n","import pickle, numpy as np, torch\n","from PIL import Image\n","from sklearn.preprocessing import normalize\n","from pathlib import Path\n","from tqdm.auto import tqdm\n","import csv\n","import matplotlib.pyplot as plt\n","from IPython.display import display\n","\n","# --- 0) Drive ê²½ë¡œ ë° íŒŒì¼ ì¡´ìž¬ ì—¬ë¶€ -----------------------------------------\n","ROOT_DRIVE = Path('/content/drive/MyDrive/image_matching_challenge')\n","WEIGHTS_OUT = ROOT_DRIVE / 'models' / f'{MODEL_NAME}_best.pth'\n","FEAT_CACHE  = ROOT_DRIVE / 'feature_spaces' / f'{MODEL_NAME}_features.npz'\n","KNN_PKL     = ROOT_DRIVE / 'models' / f'{MODEL_NAME}_knn.pkl'\n","RESULT_DIR_1 = ROOT_DRIVE / 'results' / f'{MODEL_NAME}_c2_t1_a1.csv'\n","RESULT_DIR_2 = ROOT_DRIVE / 'results' / f'{MODEL_NAME}_c2_t2_a2.csv'\n","\n","assert WEIGHTS_OUT.exists(), \"âŒ CNN ê°€ì¤‘ì¹˜(pth)ê°€ ì—†ìŠµë‹ˆë‹¤.\"\n","assert FEAT_CACHE.exists() , \"âŒ feature ìºì‹œ(npz)ê°€ ì—†ìŠµë‹ˆë‹¤.\"\n","assert KNN_PKL.exists()    , \"âŒ KNN ëª¨ë¸(pkl)ì´ ì—†ìŠµë‹ˆë‹¤.\"\n","\n","# --- 1) ëª¨ë¸ & ë³´ì¡° ê°ì²´ ë¡œë“œ -------------------------------------------------\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model, feat_forward, _ = build_model(MODEL_NAME, len(CLASS_NAMES))\n","model.load_state_dict(torch.load(WEIGHTS_OUT, map_location=device))\n","model.eval()\n","\n","# íŠ¹ì§• ë²¡í„°Â·ë ˆì´ë¸”Â·ê²½ë¡œ ë¡œë“œ (retrievalìš©)\n","data   = np.load(FEAT_CACHE, allow_pickle=True)\n","feats  = normalize(data['feats'].astype('float32'))      # L2 ì •ê·œí™” ì´ë¯¸ í–ˆìœ¼ë©´ ì œê±°\n","labels = data['labels']\n","paths  = data['paths']\n","\n","# KNN ë¡œë“œ\n","with open(KNN_PKL, 'rb') as f:\n","    knn = pickle.load(f)\n","\n","# --- 2) ì¿¼ë¦¬ ì´ë¯¸ì§€ â†’ ë¶„ë¥˜ + Retrieval ----------------------------------------\n","def classify_and_retrieve(query_paths, k=10, verbose=True, pred_csv=RESULT_DIR_1, neigh_csv=RESULT_DIR_2, show_img=True):\n","    \"\"\"\n","    Args\n","    ----\n","    query_paths : list[str | Path]\n","        ë¶„ë¥˜Â·ê²€ìƒ‰í•  ì´ë¯¸ì§€ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸\n","    k           : int, optional\n","        Retrieval ìƒìœ„ kê°œ\n","    verbose     : bool\n","        Trueë©´ ê²°ê³¼ë¥¼ print, Falseë©´ dict ë°˜í™˜ë§Œ\n","    \"\"\"\n","    pred_rows, neigh_rows = [], []      # CSVì— ì“¸ ë ˆì½”ë“œ ëˆ„ì \n","    results = []\n","\n","    for idx_query, qpath in enumerate(tqdm(query_paths, desc=\"query\")):\n","        img = Image.open(qpath).convert('RGB')\n","        if show_img:                                  # â˜… ì¶”ê°€\n","            plt.figure(figsize=(3,3))\n","            plt.imshow(img); plt.axis('off')\n","            plt.title(f\"Query {idx_query+1}: {Path(qpath).name}\")\n","            plt.show()\n","\n","\n","        x   = val_tfms(img).unsqueeze(0).to(device)      # (1,3,H,W)\n","        # 1) ë¶„ë¥˜\n","        with torch.inference_mode():\n","            logits = model(x)\n","            pred   = logits.argmax(1).item()\n","            emb_t  = F.normalize(feat_forward(x), dim=1)   # (1, D)\n","            emb    = emb_t.cpu().numpy().squeeze()\n","\n","        # 2) ê°¤ëŸ¬ë¦¬ ì „ì²´ì— ëŒ€í•œ cosineâ€†â†’â€†distance\n","        cos_all  = feats @ emb               # (N,)\n","        dist_all = 1.0 - cos_all             # (N,)\n","\n","        # 3) ì´ˆê¸° ëž­í¬ 50ê°œ â†’ k-reciprocal ìž¬ëž­í¬\n","        init_rank = dist_all.argsort()[:50]\n","        rank      = k_reciprocal_rerank(emb, feats, init_rank)\n","        final_idx = rank[:k]\n","\n","        # 4) ì´ì›ƒ ì •ë³´\n","        neigh_info = [\n","            (paths[i], CLASS_NAMES[labels[i]], float(dist_all[i]))\n","            for i in final_idx\n","        ]\n","\n","        # 5) CSVìš© í–‰\n","        qname_png   = f'query{idx_query+1:03}.png'\n","        pred_rows.append([qname_png, CLASS_NAMES[pred]])\n","\n","        neigh_labels = [CLASS_NAMES[labels[i]] for i in final_idx]\n","        neigh_rows.append([qname_png, *neigh_labels])\n","\n","        if verbose:\n","            print(f\"\\nðŸ–¼ï¸  Query: {Path(qpath).name}\")\n","            print(f\"   âž¤ Predicted class: {CLASS_NAMES[pred]}\")\n","            print(f\"   âž¤ Top-{k} nearest images\")\n","            for r, (p, cls, d) in enumerate(neigh_info, 1):\n","                print(f\"     {r:02d}. {Path(p).name:30s} | {cls:12s} | dist={d:.4f}\")\n","\n","        results.append({\n","            'query'     : str(qpath),\n","            'prediction': CLASS_NAMES[pred],\n","            'neighbors' : neigh_info\n","        })\n","\n","    with open(pred_csv,  'w', newline='') as f1:\n","      csv.writer(f1).writerows(pred_rows)\n","\n","    with open(neigh_csv, 'w', newline='') as f2:\n","      csv.writer(f2).writerows(neigh_rows)\n","\n","    print(f\"\\nâœ… Saved {len(pred_rows)} predictions â†’ {pred_csv}\")\n","    print(f\"âœ… Saved {len(neigh_rows)} neighbor lists â†’ {neigh_csv}\")\n","\n","    return results\n","\n","# --- 3) ì‚¬ìš© ì˜ˆ ---------------------------------------------------------------\n","# â‘  ë‹¨ì¼ ì´ë¯¸ì§€\n","# classify_and_retrieve(['/content/sample_data/cat.png'], k=8)\n","\n","# â‘¡ í´ë” ì•ˆ ëª¨ë“  JPG\n","query_dir = Path('/content/drive/MyDrive/image_matching_challenge/query_images')\n","valid_ext = {'.jpg', '.jpeg', '.png'}\n","query_list = sorted(p for p in query_dir.rglob('*') if p.suffix.lower() in valid_ext)\n","print(f\"â†³ found {len(query_list)} query images\")\n","classify_and_retrieve(query_list, k=10, verbose=True)\n"],"metadata":{"id":"bEkHyAXDxUSq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# --- Ensemble + Save Results Cell ---\n","from pathlib import Path\n","import torch\n","import torch.nn.functional as F\n","import numpy as np\n","from sklearn.preprocessing import normalize\n","from PIL import Image\n","import csv\n","\n","# ì‚¬ì „ ì •ì˜ë¨: build_model, val_tfms, NUM_CLASSES, CLASS_NAMES\n","\n","# 1) ëª¨ë¸ & ë°ì´í„° ê²½ë¡œ ì„¤ì •\n","MODEL_DIR   = Path('/content/drive/MyDrive/image_matching_challenge/models')\n","FEAT_DIR    = Path('/content/drive/MyDrive/image_matching_challenge/feature_spaces')\n","QUERY_DIR   = Path('/content/drive/MyDrive/image_matching_challenge/query_images')\n","RESULT_DIR  = Path('/content/drive/MyDrive/image_matching_challenge/results')\n","RESULT_DIR.mkdir(parents=True, exist_ok=True)\n","\n","# 2) ì•™ìƒë¸” ëŒ€ìƒ ëª¨ë¸ëª… ë° íŒŒì¼ëª… í”„ë¦¬í”½ìŠ¤\n","MODEL_NAMES = ['convnext_tiny', 'resnet152']\n","SAVE_PREFIX = '_'.join(MODEL_NAMES) + '_ensemble'\n","PRED_CSV    = RESULT_DIR / f\"{SAVE_PREFIX}_predictions.csv\"\n","NEIGH_CSV   = RESULT_DIR / f\"{SAVE_PREFIX}_neighbors.csv\"\n","\n","# 3) ë””ë°”ì´ìŠ¤\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# 4) ëª¨ë¸ ë¡œë“œ\n","models_dict = {}\n","for name in MODEL_NAMES:\n","    m, fwd, _ = build_model(name, NUM_CLASSES)\n","    m.load_state_dict(torch.load(MODEL_DIR/f'{name}_best.pth', map_location=device))\n","    m.to(device).eval()\n","    models_dict[name] = (m, fwd)\n","\n","# 5) í”¼ì³ ìŠ¤íŽ˜ì´ìŠ¤ ë¡œë“œ ë° ê²°í•©\n","conv = np.load(FEAT_DIR/'convnext_tiny_features.npz', allow_pickle=True)\n","res  = np.load(FEAT_DIR/'resnet152_features.npz', allow_pickle=True)\n","feats = np.concatenate([conv['feats'], res['feats']], axis=1).astype('float32')\n","feats = normalize(feats)\n","labels = conv['labels']\n","paths  = conv['paths']\n","\n","# 6) ì•™ìƒë¸” ë¶„ë¥˜+ë¦¬íŠ¸ë¦¬ë²Œ + CSV ì €ìž¥\n","\n","def ensemble_classify_and_retrieve_and_save(query_paths, k=10):\n","    pred_rows = []\n","    neigh_rows = []\n","\n","    for idx, qpath in enumerate(query_paths, start=1):\n","        img = Image.open(qpath).convert('RGB')\n","        x   = val_tfms(img).unsqueeze(0).to(device)\n","\n","        with torch.inference_mode():\n","            # logits ensemble\n","            logits = torch.stack([m(x) for m,fwd in models_dict.values()]).mean(0)\n","            pred   = logits.argmax(1).item()\n","            # embedding ensemble\n","            embs = [F.normalize(fwd(x).view(x.size(0), -1), dim=1)\n","                    for m,fwd in models_dict.values()]\n","            emb = torch.cat(embs, dim=1).cpu().numpy().squeeze()\n","\n","        # retrieval\n","        dist_all = 1.0 - (feats @ emb)\n","        idxs     = dist_all.argsort()[:k]\n","\n","        # CSV rows ì¤€ë¹„\n","        qname = f\"query{idx:03}.png\"\n","        pred_rows.append([qname, CLASS_NAMES[pred]])\n","        neigh_labels = [CLASS_NAMES[labels[i]] for i in idxs]\n","        neigh_rows.append([qname, *neigh_labels])\n","\n","    # ì €ìž¥\n","    with open(PRED_CSV, 'w', newline='') as f1:\n","        csv.writer(f1).writerows(pred_rows)\n","    with open(NEIGH_CSV, 'w', newline='') as f2:\n","        csv.writer(f2).writerows(neigh_rows)\n","\n","    print(f\"âœ… Saved predictions -> {PRED_CSV}\")\n","    print(f\"âœ… Saved neighbors   -> {NEIGH_CSV}\")\n","\n","    return pred_rows, neigh_rows\n","\n","# 7) ì‹¤í–‰\n","valid_exts = {'.jpg', '.jpeg', '.png'}\n","queries    = sorted(p for p in QUERY_DIR.rglob('*') if p.suffix.lower() in valid_exts)\n","print(f\"â†³ found {len(queries)} queries\")\n","ensemble_classify_and_retrieve_and_save(queries, k=10)\n"],"metadata":{"id":"yTD_aqWDQQ3E"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"1DphJWMGJKxD"}}]}